[ 2024-09-19 21:49:06]	fit on cpu
[ 2024-09-19 21:49:06]	model architecture: Ark(
  (encoder): ArkEncoder(
    (word_embedding): Embedding(21458, 64)
    (position_embedding): Embedding(128, 64)
    (channel_embedding): Embedding(3, 64)
    (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.5, inplace=False)
    (fusion_ch): FusionChannel(
      (lin): MultiLinear(
        (dense): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (2): Dropout(p=0.5, inplace=False)
          (3): LeakyReLU(negative_slope=0.01)
          (4): Linear(in_features=64, out_features=64, bias=True)
          (5): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (6): Dropout(p=0.5, inplace=False)
          (7): LeakyReLU(negative_slope=0.01)
        )
      )
    )
  )
  (decoder): ArkDecoder(
    (transformer_layers): TransformerLayers(
      (transformer_blocks): ModuleList(
        (0-7): 8 x TransformerLayer(
          (attention): MultiHeadAttention(
            (attention): Attention()
          )
          (ffn): PositionWiseFFN(
            (linear): MultiLinear(
              (dense): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (2): LeakyReLU(negative_slope=0.01)
                (3): Linear(in_features=64, out_features=64, bias=True)
                (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (5): LeakyReLU(negative_slope=0.01)
              )
            )
            (add_norm): AddNorm(
              (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0, inplace=False)
            )
          )
          (add_norm1): AddNorm(
            (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (add_norm2): AddNorm(
            (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.5, inplace=False)
          )
        )
      )
    )
  )
  (output_layer): ArkClassifier(
    (fusion): TransformerLayer(
      (attention): MultiHeadAttention(
        (attention): Attention()
      )
      (ffn): PositionWiseFFN(
        (linear): MultiLinear(
          (dense): Sequential(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Linear(in_features=64, out_features=64, bias=True)
            (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (5): LeakyReLU(negative_slope=0.01)
          )
        )
        (add_norm): AddNorm(
          (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0, inplace=False)
        )
      )
      (add_norm1): AddNorm(
        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (add_norm2): AddNorm(
        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (classifier): Linear(in_features=64, out_features=2, bias=True)
  )
)
[ 2024-09-19 21:49:06]	optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.01
)
[ 2024-09-19 21:49:06]	loss_fn: CrossEntropyLoss()
[ 2024-09-19 21:49:06]	num_class: 2
[ 2024-09-19 21:49:06]	epochs: 200
[ 2024-09-19 21:49:06]	stop_loss_value: 0.1
[ 2024-09-19 21:49:06]	stop_min_epoch: 20

[ 2024-09-19 21:52:23]	Epoch 10, valid loss: 0.009854739531874657
[ 2024-09-19 21:52:23]	MetricsAtEpoch: 10	Accuracy:  1.000000	Precision:  1.000000	Recall:  1.000000	F1-score:  1.000000
[ 2024-09-19 21:55:40]	Epoch 20, valid loss: 0.004948772024363279
[ 2024-09-19 21:55:40]	MetricsAtEpoch: 20	Accuracy:  1.000000	Precision:  1.000000	Recall:  1.000000	F1-score:  1.000000
[ 2024-09-19 21:56:00]	Epoch 21, valid loss: 0.004054091754369438
[ 2024-09-19 21:56:00]	MetricsAtEpoch: 21	Accuracy:  1.000000	Precision:  1.000000	Recall:  1.000000	F1-score:  1.000000
